{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Challenge: Exploratory and predictive analytics upon the comprehensive IMDb data of movies released between 1980-2020\n",
    "\n",
    "### **_by Hanlu He (s183909), Mia Hang Knudsen (s183998), Jiafei Xia (s213084), Atefeh Hemmati Golsefidi (s216676)_**\n",
    "---\n",
    "## _Report_\n",
    "---\n",
    "## Table of Contents\n",
    "- [Part 1: <u>Introduction</u>](#intro)\n",
    "- [Part 2: <u>Data analysis and visualisation</u>](#datavis)\n",
    "    - [2.1: <u>Load and present basic information of the dataset</u>](#load)\n",
    "    - [2.2: <u>Dicussion of profiler output</u>](#profiler) \n",
    "- [Part 3: <u>Prediction challenge</u>](#prediction)\n",
    "    - [3.1: <u>The expected revenue (gross)</u>](#gross)\n",
    "    - [3.2: <u>IMDb score (score)</u>](#score) \n",
    "- [Part 4: <u>Exploratory component</u>](#explore)\n",
    "    - [4.1: <u>Q1</u>](#q1)\n",
    "    - [4.2: <u>Q2</u>](#q2)\n",
    "- [Part 5: <u>Conclusion</u>](#conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (18, 8)\n",
    "sns.set_theme()\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='intro'></a>\n",
    "## Part 1: _<u>Introduction</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with dataset obtained through kaggle called [Comprehensive IMDb Data](https://www.kaggle.com/austinwolff/comprehensive-imdb-data). The dataset contains movies released in the USA between 1980-2020 that has available box office data. The dataset was created with the intention of what features/variables contribute most to the movie's box office success. Below is the features list that are included in the dataset.\n",
    "\n",
    "**Features**\n",
    "\n",
    "* **titleId**: IMDb's relational database ID for \"title\".\n",
    "* **title**: Title of the movie.\n",
    "* **rating**: MPAA (Motion Picture Association of America film rating system ) rating. \n",
    "* **region**: Region. \n",
    "* **genre**: The movie genre.\n",
    "* **released**: Release date of the movie in theaters.\n",
    "* **year**: Year of movie release.\n",
    "* **month**: Month of movie release.\n",
    "* **day**: Day of movie release.\n",
    "* **score**: IMDb score.\n",
    "* **director**: Director of the movie.\n",
    "* **writer**: Writer of the movie.\n",
    "* **star**: Main actor and actress of the movie.\n",
    "* **country**: Main country of the movie.\n",
    "* **budget**: Budget of the movie.\n",
    "* **gross**: Gross revenue (box office) of the movie.\n",
    "* **company**: Production company of the movie.\n",
    "* **runtime**: Runtime of the movie in minutes. \n",
    "* **category**: Type of the credit this person (\"primaryName\") had for working on the movie. \n",
    "* **nconst**: IMDb's relational database ID for \"primaryName\".\n",
    "* **primaryName**: Name of person who worked on the movie.\n",
    "* **knownForTitles**: Top 4 titles an actor (indicated by \"primaryName\") is known for, by titleID. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='datavis'></a>\n",
    "## Part 2: _<u>Data analysis and visualisation</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='prediction'></a>\n",
    "## Part 3: _<u>Prediction challenge</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gross'></a>\n",
    "### 3.1: _<u>The expected revenue (gross)</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='score'></a>\n",
    "### 3.2: _<u>IMDb score (score)</u>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_movies = preprocess('Comprehensive IMDb Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_movies.copy(deep=True)  #Pandas' deep copy does not work so the orgianl will still be changed\n",
    "# Finding and binarize the features with the top 30 most commen \\n\",\n",
    "train = binary_features(df_movies, ['director','writer','star','country','company','primaryName'], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_year</th>\n",
       "      <th>titleId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>genre</th>\n",
       "      <th>released</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>director_Ron Howard</th>\n",
       "      <th>director_Sam Raimi</th>\n",
       "      <th>director_Spike Lee</th>\n",
       "      <th>director_Steven Soderbergh</th>\n",
       "      <th>director_Steven Spielberg</th>\n",
       "      <th>director_Tim Burton</th>\n",
       "      <th>director_Tony Scott</th>\n",
       "      <th>director_Walter Hill</th>\n",
       "      <th>director_Wes Craven</th>\n",
       "      <th>director_Woody Allen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Gigolo_1980</td>\n",
       "      <td>[tt0080365, tt4257262]</td>\n",
       "      <td>American Gigolo</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>1980-02-01</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fog_1980</td>\n",
       "      <td>[tt0014051, tt0058270, tt0080749, tt0432291, t...</td>\n",
       "      <td>The Fog</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1980-02-08</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruising_1980</td>\n",
       "      <td>[tt0080569, tt3696404, tt4828890]</td>\n",
       "      <td>Cruising</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>1980-02-15</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Time Ran Out..._1980</td>\n",
       "      <td>[tt0081747]</td>\n",
       "      <td>When Time Ran Out...</td>\n",
       "      <td>PG</td>\n",
       "      <td>US</td>\n",
       "      <td>Action</td>\n",
       "      <td>1980-03-28</td>\n",
       "      <td>1980</td>\n",
       "      <td>March</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heaven's Gate_1980</td>\n",
       "      <td>[tt0080855, tt11210146, tt12892296, tt14807362...</td>\n",
       "      <td>Heaven's Gate</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1980-04-24</td>\n",
       "      <td>1980</td>\n",
       "      <td>April</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>Cronos_1994</td>\n",
       "      <td>[tt0104029, tt14811148, tt5692086, tt6056746]</td>\n",
       "      <td>Cronos</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1994</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>My Brother's Wedding_1985</td>\n",
       "      <td>[tt0087763, tt1051850]</td>\n",
       "      <td>My Brother's Wedding</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>US</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1985</td>\n",
       "      <td>March</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>Come See the Paradise_1991</td>\n",
       "      <td>[tt0099291]</td>\n",
       "      <td>Come See the Paradise</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1991</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>Getting It on_1983</td>\n",
       "      <td>[tt0085588]</td>\n",
       "      <td>Getting It on</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1983</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>Liebestraum_1991</td>\n",
       "      <td>[tt0102299, tt9915736]</td>\n",
       "      <td>Liebestraum</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1991</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5304 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title_year  \\\n",
       "0           American Gigolo_1980   \n",
       "1                   The Fog_1980   \n",
       "2                  Cruising_1980   \n",
       "3      When Time Ran Out..._1980   \n",
       "4             Heaven's Gate_1980   \n",
       "...                          ...   \n",
       "5299                 Cronos_1994   \n",
       "5300   My Brother's Wedding_1985   \n",
       "5301  Come See the Paradise_1991   \n",
       "5302          Getting It on_1983   \n",
       "5303            Liebestraum_1991   \n",
       "\n",
       "                                                titleId  \\\n",
       "0                                [tt0080365, tt4257262]   \n",
       "1     [tt0014051, tt0058270, tt0080749, tt0432291, t...   \n",
       "2                     [tt0080569, tt3696404, tt4828890]   \n",
       "3                                           [tt0081747]   \n",
       "4     [tt0080855, tt11210146, tt12892296, tt14807362...   \n",
       "...                                                 ...   \n",
       "5299      [tt0104029, tt14811148, tt5692086, tt6056746]   \n",
       "5300                             [tt0087763, tt1051850]   \n",
       "5301                                        [tt0099291]   \n",
       "5302                                        [tt0085588]   \n",
       "5303                             [tt0102299, tt9915736]   \n",
       "\n",
       "                      title     rating region      genre   released  year  \\\n",
       "0           American Gigolo          R     US      Crime 1980-02-01  1980   \n",
       "1                   The Fog          R     US     Horror 1980-02-08  1980   \n",
       "2                  Cruising          R     US      Crime 1980-02-15  1980   \n",
       "3      When Time Ran Out...         PG     US     Action 1980-03-28  1980   \n",
       "4             Heaven's Gate          R     US  Adventure 1980-04-24  1980   \n",
       "...                     ...        ...    ...        ...        ...   ...   \n",
       "5299                 Cronos          R     US    Fantasy        NaT  1994   \n",
       "5300   My Brother's Wedding  Not Rated     US      Drama        NaT  1985   \n",
       "5301  Come See the Paradise          R     US      Drama        NaT  1991   \n",
       "5302          Getting It on          R     US     Comedy        NaT  1983   \n",
       "5303            Liebestraum          R     US    Mystery        NaT  1991   \n",
       "\n",
       "         month   day  ...  director_Ron Howard director_Sam Raimi  \\\n",
       "0     February   1.0  ...                  0.0                0.0   \n",
       "1     February   8.0  ...                  0.0                0.0   \n",
       "2     February  15.0  ...                  0.0                0.0   \n",
       "3        March  28.0  ...                  0.0                0.0   \n",
       "4        April  24.0  ...                  0.0                0.0   \n",
       "...        ...   ...  ...                  ...                ...   \n",
       "5299       May   NaN  ...                  0.0                0.0   \n",
       "5300     March   NaN  ...                  0.0                0.0   \n",
       "5301   January   NaN  ...                  0.0                0.0   \n",
       "5302    August   NaN  ...                  0.0                0.0   \n",
       "5303  November   NaN  ...                  0.0                0.0   \n",
       "\n",
       "     director_Spike Lee director_Steven Soderbergh director_Steven Spielberg  \\\n",
       "0                   0.0                        0.0                       0.0   \n",
       "1                   0.0                        0.0                       0.0   \n",
       "2                   0.0                        0.0                       0.0   \n",
       "3                   0.0                        0.0                       0.0   \n",
       "4                   0.0                        0.0                       0.0   \n",
       "...                 ...                        ...                       ...   \n",
       "5299                0.0                        0.0                       0.0   \n",
       "5300                0.0                        0.0                       0.0   \n",
       "5301                0.0                        0.0                       0.0   \n",
       "5302                0.0                        0.0                       0.0   \n",
       "5303                0.0                        0.0                       0.0   \n",
       "\n",
       "      director_Tim Burton  director_Tony Scott director_Walter Hill  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "1                     0.0                  0.0                  0.0   \n",
       "2                     0.0                  0.0                  0.0   \n",
       "3                     0.0                  0.0                  0.0   \n",
       "4                     0.0                  0.0                  0.0   \n",
       "...                   ...                  ...                  ...   \n",
       "5299                  0.0                  0.0                  0.0   \n",
       "5300                  0.0                  0.0                  0.0   \n",
       "5301                  0.0                  0.0                  0.0   \n",
       "5302                  0.0                  0.0                  0.0   \n",
       "5303                  0.0                  0.0                  0.0   \n",
       "\n",
       "      director_Wes Craven director_Woody Allen  \n",
       "0                     0.0                  0.0  \n",
       "1                     0.0                  0.0  \n",
       "2                     0.0                  0.0  \n",
       "3                     0.0                  0.0  \n",
       "4                     0.0                  0.0  \n",
       "...                   ...                  ...  \n",
       "5299                  0.0                  0.0  \n",
       "5300                  0.0                  0.0  \n",
       "5301                  0.0                  0.0  \n",
       "5302                  0.0                  0.0  \n",
       "5303                  0.0                  0.0  \n",
       "\n",
       "[5304 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_movies.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-73dd015af7c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "temp = train[feature]\n",
    "\n",
    "#[g for g in temp[0] or []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-03eab0709045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmost_30\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m                 )\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-03eab0709045>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmost_30\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "feature = 'primaryName'\n",
    "train[feature]= train[feature].apply(lambda x:[g for g in x or []])\n",
    "c = Counter(sum(train[feature], []))\n",
    "most_30 = [x[0] for x in c.most_common(30)]\n",
    "train['temp_30'] = train[feature].apply(lambda x: list(set(most_30) & set(x)))\n",
    "dummies = pd.get_dummies(train['temp_30'].apply(pd.Series).stack(), prefix = feature).groupby(level=0).sum()\n",
    "\n",
    "# Join back with the original dataframe \n",
    "train = train.join(dummies)#.fillna(0)\n",
    "train.iloc[:,-30:] = train.iloc[:,29:].fillna(0)\n",
    "train.drop(columns=['temp_30'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director\n",
      "writer\n",
      "star\n",
      "country\n",
      "company\n",
      "primaryName\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Finding and binarize the features with the top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#df, df_movies = preprocess('Comprehensive IMDb Data.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_movies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'director'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'writer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'star'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36mbinary_features\u001b[1;34m(train, features)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Extract information from dict and convert to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Finding top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m                 )\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Extract information from dict and convert to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Finding top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Define function for binarization of columns with the top 30 most commen ones\n",
    "\n",
    "def binary_features(train, features): \n",
    "    for feature in features:\n",
    "        print(feature)\n",
    "        # Extract information from dict and convert to list \n",
    "        train[feature]= train[feature].apply(lambda x:[x or []])\n",
    "\n",
    "        # Finding top 30 most commen \n",
    "        c = Counter(sum(train[feature], []))\n",
    "        most_30 = [x[0] for x in c.most_common(30)]\n",
    "\n",
    "        # Removing the ones that are not in the top 30 \n",
    "        train['temp_30'] = train[feature].apply(lambda x: list(set(most_30) & set(x)))\n",
    "\n",
    "        # Creat dummies \n",
    "        dummies = pd.get_dummies(train['temp_30'].apply(pd.Series).stack(), prefix = feature).groupby(level=0).sum()\n",
    "\n",
    "        # Join back with the original dataframe \n",
    "        train = train.join(dummies)\n",
    "        train.iloc[:,-30:] = train.iloc[:,-30:].fillna(0)\n",
    "\n",
    "        # Drop the temperary colum \n",
    "        train.drop(columns=['temp_30'], inplace=True)\n",
    "    return train\n",
    "\n",
    "# Finding and binarize the features with the top 30 most commen \n",
    "#df, df_movies = preprocess('Comprehensive IMDb Data.csv')\n",
    "train = binary_features(df_movies, ['director','writer','star','country','company','primaryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
>>>>>>> 9d800f417920792217eade7eb10b8c026fd87051
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='explore'></a>\n",
    "## Part 4: _<u>Exploratory component</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='conc'></a>\n",
    "## Part 5: _<u>Conclusion</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    ## create unique identifier of each movie \n",
    "    df['title_year'] = df['title'] + '_' + df['year'].astype(str)\n",
    "    ## create profit column\n",
    "    df['Profit'] = df['gross'] - df['budget']\n",
    "\n",
    "    #########################################################################################\n",
    "    ## create new compact datarfame\n",
    "    ## extract list of unique movie titles \n",
    "    #titles=list(set(df['title']))\n",
    "    title_year_set = list(set(df['title_year']))\n",
    "\n",
    "    # Create a dataframe where each row is a unique movie \n",
    "    movies={}\n",
    "    for t in title_year_set:\n",
    "        # Create a temperary datframe for subset of with title_year = t\n",
    "        df_temp = df[df.title_year == t]\n",
    "\n",
    "        # Extracting all the unique values for the attributes for the given title_year t\n",
    "        star = np.unique(df_temp['star'])\n",
    "        writer = np.unique(df_temp['writer'])\n",
    "        director = np.unique(df_temp['director'])\n",
    "        title = np.unique(df_temp['title'])\n",
    "        rating = np.unique(df_temp['rating'])\n",
    "        genre =np.unique(df_temp['genre'])\n",
    "        released = np.unique(df_temp['released'])\n",
    "        year = np.unique(df_temp['year'])\n",
    "        month = np.unique(df_temp['month'])\n",
    "        day = np.unique(df_temp['day'])\n",
    "        score = np.unique(df_temp['score'])\n",
    "        country = np.unique(df_temp['country'])\n",
    "        budget = np.unique(df_temp['budget'])\n",
    "        gross = np.unique(df_temp['gross'])\n",
    "        company = np.unique(df_temp['company'])\n",
    "        runtime = np.unique(df_temp['runtime'])\n",
    "        region = np.unique(df_temp['region'])\n",
    "        titleId = np.unique(df_temp['titleId'])\n",
    "        primaryName = np.unique(df_temp['primaryName'])\n",
    "\n",
    "        # Extract attributes which are based on primaryName and then as dictionaries\n",
    "        cat = {}\n",
    "        ncon = {}\n",
    "        prim = {}\n",
    "        known = {}\n",
    "        for index, row in df[df.title_year == t].iterrows():\n",
    "            pN = row['primaryName']\n",
    "            cat[pN] = row['category']\n",
    "            ncon[pN] = row['nconst']\n",
    "            known[pN] = row['knownForTitles']\n",
    "\n",
    "        movie = {'titleId': titleId, 'title':title, 'rating':rating, 'region':region, 'genre': genre, 'released': released, 'year':year,\n",
    "        'month':month, 'day':day, 'score':score, 'director':director, 'writer':writer, 'star':star, 'country':country,\n",
    "        'budget':budget, 'gross':gross, 'company':company, 'runtime': runtime, 'primaryName':primaryName, 'category':cat, 'nconst':ncon, 'knownForTitles':known}\n",
    "        movies[t]=movie\n",
    "    \n",
    "    # Construct dataframe \n",
    "    d=pd.DataFrame(movies)\n",
    "    df2=d.transpose()\n",
    "\n",
    "    df_movies = df2.copy()\n",
    "    # Finding one value for budget for each title_year\n",
    "    df_movies['budget'] = df_movies['budget'].apply(lambda x: x if len(x) == 1 else [np.nanmean(x)])\n",
    "\n",
    "    # Unpack array\n",
    "    col_unpack = ['title', 'rating', 'region', 'genre', 'released', 'year', 'month',\n",
    "        'day', 'score', 'director', 'writer', 'star', 'country', 'budget',\n",
    "        'gross', 'company', 'runtime']\n",
    "        \n",
    "    for col in col_unpack:\n",
    "        df_movies[col] = [i[0] for i in df_movies[col]]\n",
    "\n",
    "    #############################################################################\n",
    "    ## Data cleaning\n",
    "\n",
    "    # Drop missing values in budget\n",
    "    df_movies = df_movies.dropna(subset=['budget'])\n",
    "    # Dealing with missing values in rating\n",
    "    df_movies['rating'].fillna(\"Not Rated\", inplace = True) \n",
    "    df_movies['rating'] = df_movies['rating'].replace(['Unrated'],'Not Rated')\n",
    "    df_movies.fillna({'country':df_movies.country.mode().astype(str)[0],\n",
    "    'company':df_movies.company.mode().astype(str)[0],'runtime':df_movies.runtime.median()},inplace=True)\n",
    "\n",
    "    df_movies = df_movies.dropna(subset=['month'])\n",
    "\n",
    "    df_movies['released'] = pd.to_datetime(df_movies['released'],format='%Y-%m-%d')\n",
    "    df_movies = df_movies.sort_values(by= ['released'])\n",
    "\n",
    "    # Chagne type of month\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    df_movies['months'] = pd.Categorical(df_movies['month'], categories=months, ordered=True)\n",
    "\n",
    "    # Convert the gross and budget from $ to Million $ \n",
    "    df_movies['gross'] = df_movies['gross']/1000000\n",
    "    df_movies['budget'] = df_movies['budget']/1000000\n",
    "\n",
    "    df_movies = df_movies.reset_index().rename(columns = {'index':'title_year'})\n",
    "\n",
    "    ####################################################################################\n",
    "    ## add new features to df_movies\n",
    "\n",
    "    df_movies['Profit'] = df_movies['gross'] - df_movies['budget']\n",
    "\n",
    "    ## we will create new column called released_2 that only consists of year and month information of movie release\n",
    "    df_movies['released_2'] = str(df_movies['year']) + '_' + str(df_movies['month'])\n",
    "\n",
    "    df_movies['country'] = df_movies['country'].replace(['West Germany'],'Germany')\n",
    "    df_movies['country'] = df_movies['country'].replace(['Yugoslavia'],'Serbia')\n",
    "    df_movies['country'] = df_movies['country'].replace(['Federal Republic of Yugoslavia'],'Serbia')\n",
    "\n",
    "    df_movies['continent'] = df_movies['country'].apply(country_to_continent)\n",
    "\n",
    "    # Create duration column\n",
    "    df_movies['duration'] = df_movies['runtime'].apply(duration)\n",
    "\n",
    "    return df,df_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define function for binarization of columns with the top N most commen ones\n",
    "def binary_features(train, features, N):\n",
    "    for feature in features:\n",
    "        # Extract information and convert to list\n",
    "        if feature == 'primaryName':\n",
    "            train[feature]= train[feature].apply(lambda x:[g for g in x])\n",
    "        else:\n",
    "            train[feature]= train[feature].apply(lambda x:[x or []])\n",
    "\n",
    "        # Finding top 30 most commen\n",
    "        c = Counter(sum(train[feature], []))\n",
    "        most_N = [x[0] for x in c.most_common(N)]\n",
    " \n",
    "        # Removing the ones that are not in the top 30 \n",
    "        train['temp_N'] = train[feature].apply(lambda x: list(set(most_N) & set(x)))\n",
    "\n",
    "        # Creat dummies \n",
    "        dummies = pd.get_dummies(train['temp_N'].apply(pd.Series).stack(), prefix = feature).groupby(level=0).sum()\n",
    "\n",
    "        # Join back with the original dataframe\n",
    "        train = train.join(dummies)\n",
    "        train.iloc[:,-N:] = train.iloc[:,-N:].fillna(0)\n",
    "    \n",
    "        # Drop the temperary colum \n",
    "        train.drop(columns=['temp_N'], inplace=True)\n",
    "        return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "def country_to_continent(country_name):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "\n",
    "def duration(x):\n",
    "    if x <= 120:\n",
    "        return 'Short'\n",
    "    else:\n",
    "        return 'Long'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1d60ef3148d6d6f99d64de6ef09e0267d4db5c62a0823eaf2b9aa582c08f8e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
