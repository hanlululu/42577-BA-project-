{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Challenge: Exploratory and predictive analytics upon the comprehensive IMDb data of movies released between 1980-2020\n",
    "\n",
    "### **_by Hanlu He (s183909), Mia Hang Knudsen (s183998), Jiafei Xia (s213084), Atefeh Hemmati Golsefidi (s216676)_**\n",
    "---\n",
    "## _Notebook 1/2: Exploratory analysis of data_\n",
    "---\n",
    "## Table of Contents\n",
    "- [Part 1: <u>Introduction</u>](#intro)\n",
    "- [Part 2: <u>Data analysis and visualisation</u>](#datavis)\n",
    "    - [2.1: <u>Load and present basic information of the dataset</u>](#load)\n",
    "    - [2.2: <u>Dicussion of profiler output</u>](#profiler) \n",
    "- [Part 3: <u>Prediction challenge</u>](#prediction)\n",
    "    - [2.1: <u>The expected revenue (gross)</u>](#gross)\n",
    "    - [2.2: <u>IMDb score (score)</u>](#score) \n",
    "- [Part 4: <u>Exploratory component</u>](#explore)\n",
    "    - [4.1: <u>Q1</u>](#q1)\n",
    "    - [4.2: <u>Q2</u>](#q2)\n",
    "- [Part 5: <u>Conclusion</u>](#conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (18, 8)\n",
    "sns.set_theme()\n",
    "from ipywidgets import interact\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='intro'></a>\n",
    "## Part 1: _<u>Introduction</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with dataset obtained through kaggle called [Comprehensive IMDb Data](https://www.kaggle.com/austinwolff/comprehensive-imdb-data). The dataset contains movies released in the USA between 1980-2020 that has available box office data. The dataset was created with the intention of what features/variables contribute most to the movie's box office success. Below is the features list that are included in the dataset.\n",
    "\n",
    "**Features**\n",
    "\n",
    "* **titleId**: IMDb's relational database ID for \"title\".\n",
    "* **title**: Title of the movie.\n",
    "* **rating**: MPAA (Motion Picture Association of America film rating system ) rating. \n",
    "* **region**: Region. \n",
    "* **genre**: The movie genre.\n",
    "* **released**: Release date of the movie in theaters.\n",
    "* **year**: Year of movie release.\n",
    "* **month**: Month of movie release.\n",
    "* **day**: Day of movie release.\n",
    "* **score**: IMDb score.\n",
    "* **director**: Director of the movie.\n",
    "* **writer**: Writer of the movie.\n",
    "* **star**: Main actor and actress of the movie.\n",
    "* **country**: Main country of the movie.\n",
    "* **budget**: Budget of the movie.\n",
    "* **gross**: Gross revenue (box office) of the movie.\n",
    "* **company**: Production company of the movie.\n",
    "* **runtime**: Runtime of the movie in minutes. \n",
    "* **category**: Type of the credit this person (\"primaryName\") had for working on the movie. \n",
    "* **nconst**: IMDb's relational database ID for \"primaryName\".\n",
    "* **primaryName**: Name of person who worked on the movie.\n",
    "* **knownForTitles**: Top 4 titles an actor (indicated by \"primaryName\") is known for, by titleID. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='datavis'></a>\n",
    "## Part 2: _<u>Data analysis and visualisation</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='prediction'></a>\n",
    "## Part 3: _<u>Prediction challenge</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gross'></a>\n",
    "### 3.1: _<u>The expected revenue (gross)</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='score'></a>\n",
    "### 3.2: _<u>IMDb score (score)</u>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanlu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "df, df_movies = preprocess('Comprehensive IMDb Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_year</th>\n",
       "      <th>titleId</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>genre</th>\n",
       "      <th>released</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>runtime</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>category</th>\n",
       "      <th>nconst</th>\n",
       "      <th>knownForTitles</th>\n",
       "      <th>months</th>\n",
       "      <th>Profit</th>\n",
       "      <th>released_2</th>\n",
       "      <th>continent</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Gigolo_1980</td>\n",
       "      <td>[tt0080365, tt4257262]</td>\n",
       "      <td>American Gigolo</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>1980-02-01</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>[Christopher M. Campos, Gretchen Mol, Hector E...</td>\n",
       "      <td>{'Jerry Bruckheimer': 'producer', 'Jon Berntha...</td>\n",
       "      <td>{'Jerry Bruckheimer': 'nm0000988', 'Jon Bernth...</td>\n",
       "      <td>{'Jerry Bruckheimer': 'tt0449088,tt0210945,tt0...</td>\n",
       "      <td>February</td>\n",
       "      <td>17.943674</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fog_1980</td>\n",
       "      <td>[tt0014051, tt0058270, tt0080749, tt0432291, t...</td>\n",
       "      <td>The Fog</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1980-02-08</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>[Adrienne Barbeau, Allison Minick, Annie Hamil...</td>\n",
       "      <td>{'Tarun Bose': 'actor', 'Madan Puri': 'actor',...</td>\n",
       "      <td>{'Tarun Bose': 'nm0097905', 'Madan Puri': 'nm0...</td>\n",
       "      <td>{'Tarun Bose': 'tt0057332,tt0247394,tt0349634,...</td>\n",
       "      <td>February</td>\n",
       "      <td>20.448782</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruising_1980</td>\n",
       "      <td>[tt0080569, tt3696404, tt4828890]</td>\n",
       "      <td>Cruising</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>1980-02-15</td>\n",
       "      <td>1980</td>\n",
       "      <td>February</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>[Al Pacino, Bud S. Smith, Gerald Walker, Jerry...</td>\n",
       "      <td>{'Karen Allen': 'actress', 'Gerald Walker': 'w...</td>\n",
       "      <td>{'Karen Allen': 'nm0000261', 'Gerald Walker': ...</td>\n",
       "      <td>{'Karen Allen': 'tt0088172,tt0082971,tt0077975...</td>\n",
       "      <td>February</td>\n",
       "      <td>8.814523</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Time Ran Out..._1980</td>\n",
       "      <td>[tt0081747]</td>\n",
       "      <td>When Time Ran Out...</td>\n",
       "      <td>PG</td>\n",
       "      <td>US</td>\n",
       "      <td>Action</td>\n",
       "      <td>1980-03-28</td>\n",
       "      <td>1980</td>\n",
       "      <td>March</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>[Carl Foreman, Edward Albert, Gordon Thomas, I...</td>\n",
       "      <td>{'Gordon Thomas': 'writer', 'Jacqueline Bisset...</td>\n",
       "      <td>{'Gordon Thomas': 'nm0858883', 'Jacqueline Bis...</td>\n",
       "      <td>{'Gordon Thomas': 'tt0162829,tt0075406,tt04046...</td>\n",
       "      <td>March</td>\n",
       "      <td>-16.236012</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heaven's Gate_1980</td>\n",
       "      <td>[tt0080855, tt11210146, tt12892296, tt14807362...</td>\n",
       "      <td>Heaven's Gate</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1980-04-24</td>\n",
       "      <td>1980</td>\n",
       "      <td>April</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>[A. Marshal Ward, Alessandro Zangirolami, Barr...</td>\n",
       "      <td>{'Joe Ballew': 'actor', 'A. Marshal Ward': 'ac...</td>\n",
       "      <td>{'Joe Ballew': 'nm6007580', 'A. Marshal Ward':...</td>\n",
       "      <td>{'Joe Ballew': 'tt3774094,tt3317000,tt5609730,...</td>\n",
       "      <td>April</td>\n",
       "      <td>-40.515477</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>Killing Zoe_1994</td>\n",
       "      <td>[tt0110265]</td>\n",
       "      <td>Killing Zoe</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1994</td>\n",
       "      <td>September</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[David Wasco, Eric Pascal Chaltiel, Eric Stolt...</td>\n",
       "      <td>{'Roger Avary': 'director', 'Samuel Hadida': '...</td>\n",
       "      <td>{'Roger Avary': 'nm0000812', 'Samuel Hadida': ...</td>\n",
       "      <td>{'Roger Avary': 'tt7248248,tt0110912,tt0110265...</td>\n",
       "      <td>September</td>\n",
       "      <td>-1.081039</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>Cronos_1994</td>\n",
       "      <td>[tt0104029, tt14811148, tt5692086, tt6056746]</td>\n",
       "      <td>Cronos</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1994</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>[Arthur Gorson, Austin Witt, Bertha Navarro, C...</td>\n",
       "      <td>{'Sandra Mitrovic': 'producer', 'Yu-Ting Lin':...</td>\n",
       "      <td>{'Sandra Mitrovic': 'nm5972991', 'Yu-Ting Lin'...</td>\n",
       "      <td>{'Sandra Mitrovic': 'tt6076042,tt2402157,tt102...</td>\n",
       "      <td>May</td>\n",
       "      <td>-1.378608</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>Getting It on_1983</td>\n",
       "      <td>[tt0085588]</td>\n",
       "      <td>Getting It on</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1983</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>[Heather Kennedy, Jeff Edmond, Kathy Brickmeie...</td>\n",
       "      <td>{'William Olsen': 'director', 'Heather Kennedy...</td>\n",
       "      <td>{'William Olsen': 'nm0003572', 'Heather Kenned...</td>\n",
       "      <td>{'William Olsen': 'tt0120173,tt0096770,tt00855...</td>\n",
       "      <td>August</td>\n",
       "      <td>0.755414</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>Penelope_2006</td>\n",
       "      <td>[tt0060818, tt0472160, tt1119944, tt11646296, ...</td>\n",
       "      <td>Penelope</td>\n",
       "      <td>PG</td>\n",
       "      <td>US</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2006</td>\n",
       "      <td>February</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[Agustin Adba, Alex Legend, Alexa Servodidio, ...</td>\n",
       "      <td>{'Dick Shawn': 'actor', 'Scarlett Urbano': 'di...</td>\n",
       "      <td>{'Dick Shawn': 'nm0790071', 'Scarlett Urbano':...</td>\n",
       "      <td>{'Dick Shawn': 'tt0118688,tt0057193,tt0063462,...</td>\n",
       "      <td>February</td>\n",
       "      <td>6.156270</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>Stormy Monday_1988</td>\n",
       "      <td>[tt0096180]</td>\n",
       "      <td>Stormy Monday</td>\n",
       "      <td>R</td>\n",
       "      <td>US</td>\n",
       "      <td>Crime</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1988</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[Andrew McAlpine, David Martin, Melanie Griffi...</td>\n",
       "      <td>{'Sean Bean': 'actor', 'Nigel Stafford-Clark':...</td>\n",
       "      <td>{'Sean Bean': 'nm0000293', 'Nigel Stafford-Cla...</td>\n",
       "      <td>{'Sean Bean': 'tt0944947,tt0167261,tt1181791,t...</td>\n",
       "      <td>May</td>\n",
       "      <td>-2.208672</td>\n",
       "      <td>0       1980\\n1       1980\\n2       1980\\n3   ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5304 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title_year  \\\n",
       "0          American Gigolo_1980   \n",
       "1                  The Fog_1980   \n",
       "2                 Cruising_1980   \n",
       "3     When Time Ran Out..._1980   \n",
       "4            Heaven's Gate_1980   \n",
       "...                         ...   \n",
       "5299           Killing Zoe_1994   \n",
       "5300                Cronos_1994   \n",
       "5301         Getting It on_1983   \n",
       "5302              Penelope_2006   \n",
       "5303         Stormy Monday_1988   \n",
       "\n",
       "                                                titleId                 title  \\\n",
       "0                                [tt0080365, tt4257262]       American Gigolo   \n",
       "1     [tt0014051, tt0058270, tt0080749, tt0432291, t...               The Fog   \n",
       "2                     [tt0080569, tt3696404, tt4828890]              Cruising   \n",
       "3                                           [tt0081747]  When Time Ran Out...   \n",
       "4     [tt0080855, tt11210146, tt12892296, tt14807362...         Heaven's Gate   \n",
       "...                                                 ...                   ...   \n",
       "5299                                        [tt0110265]           Killing Zoe   \n",
       "5300      [tt0104029, tt14811148, tt5692086, tt6056746]                Cronos   \n",
       "5301                                        [tt0085588]         Getting It on   \n",
       "5302  [tt0060818, tt0472160, tt1119944, tt11646296, ...              Penelope   \n",
       "5303                                        [tt0096180]         Stormy Monday   \n",
       "\n",
       "     rating region      genre   released  year      month   day  ...  runtime  \\\n",
       "0         R     US      Crime 1980-02-01  1980   February   1.0  ...    117.0   \n",
       "1         R     US     Horror 1980-02-08  1980   February   8.0  ...     89.0   \n",
       "2         R     US      Crime 1980-02-15  1980   February  15.0  ...    102.0   \n",
       "3        PG     US     Action 1980-03-28  1980      March  28.0  ...    121.0   \n",
       "4         R     US  Adventure 1980-04-24  1980      April  24.0  ...    219.0   \n",
       "...     ...    ...        ...        ...   ...        ...   ...  ...      ...   \n",
       "5299      R     US      Crime        NaT  1994  September   NaN  ...     96.0   \n",
       "5300      R     US    Fantasy        NaT  1994        May   NaN  ...     94.0   \n",
       "5301      R     US     Comedy        NaT  1983     August   NaN  ...     96.0   \n",
       "5302     PG     US     Comedy        NaT  2006   February  29.0  ...    104.0   \n",
       "5303      R     US      Crime        NaT  1988        May   NaN  ...     93.0   \n",
       "\n",
       "                                            primaryName  \\\n",
       "0     [Christopher M. Campos, Gretchen Mol, Hector E...   \n",
       "1     [Adrienne Barbeau, Allison Minick, Annie Hamil...   \n",
       "2     [Al Pacino, Bud S. Smith, Gerald Walker, Jerry...   \n",
       "3     [Carl Foreman, Edward Albert, Gordon Thomas, I...   \n",
       "4     [A. Marshal Ward, Alessandro Zangirolami, Barr...   \n",
       "...                                                 ...   \n",
       "5299  [David Wasco, Eric Pascal Chaltiel, Eric Stolt...   \n",
       "5300  [Arthur Gorson, Austin Witt, Bertha Navarro, C...   \n",
       "5301  [Heather Kennedy, Jeff Edmond, Kathy Brickmeie...   \n",
       "5302  [Agustin Adba, Alex Legend, Alexa Servodidio, ...   \n",
       "5303  [Andrew McAlpine, David Martin, Melanie Griffi...   \n",
       "\n",
       "                                               category  \\\n",
       "0     {'Jerry Bruckheimer': 'producer', 'Jon Berntha...   \n",
       "1     {'Tarun Bose': 'actor', 'Madan Puri': 'actor',...   \n",
       "2     {'Karen Allen': 'actress', 'Gerald Walker': 'w...   \n",
       "3     {'Gordon Thomas': 'writer', 'Jacqueline Bisset...   \n",
       "4     {'Joe Ballew': 'actor', 'A. Marshal Ward': 'ac...   \n",
       "...                                                 ...   \n",
       "5299  {'Roger Avary': 'director', 'Samuel Hadida': '...   \n",
       "5300  {'Sandra Mitrovic': 'producer', 'Yu-Ting Lin':...   \n",
       "5301  {'William Olsen': 'director', 'Heather Kennedy...   \n",
       "5302  {'Dick Shawn': 'actor', 'Scarlett Urbano': 'di...   \n",
       "5303  {'Sean Bean': 'actor', 'Nigel Stafford-Clark':...   \n",
       "\n",
       "                                                 nconst  \\\n",
       "0     {'Jerry Bruckheimer': 'nm0000988', 'Jon Bernth...   \n",
       "1     {'Tarun Bose': 'nm0097905', 'Madan Puri': 'nm0...   \n",
       "2     {'Karen Allen': 'nm0000261', 'Gerald Walker': ...   \n",
       "3     {'Gordon Thomas': 'nm0858883', 'Jacqueline Bis...   \n",
       "4     {'Joe Ballew': 'nm6007580', 'A. Marshal Ward':...   \n",
       "...                                                 ...   \n",
       "5299  {'Roger Avary': 'nm0000812', 'Samuel Hadida': ...   \n",
       "5300  {'Sandra Mitrovic': 'nm5972991', 'Yu-Ting Lin'...   \n",
       "5301  {'William Olsen': 'nm0003572', 'Heather Kenned...   \n",
       "5302  {'Dick Shawn': 'nm0790071', 'Scarlett Urbano':...   \n",
       "5303  {'Sean Bean': 'nm0000293', 'Nigel Stafford-Cla...   \n",
       "\n",
       "                                         knownForTitles     months     Profit  \\\n",
       "0     {'Jerry Bruckheimer': 'tt0449088,tt0210945,tt0...   February  17.943674   \n",
       "1     {'Tarun Bose': 'tt0057332,tt0247394,tt0349634,...   February  20.448782   \n",
       "2     {'Karen Allen': 'tt0088172,tt0082971,tt0077975...   February   8.814523   \n",
       "3     {'Gordon Thomas': 'tt0162829,tt0075406,tt04046...      March -16.236012   \n",
       "4     {'Joe Ballew': 'tt3774094,tt3317000,tt5609730,...      April -40.515477   \n",
       "...                                                 ...        ...        ...   \n",
       "5299  {'Roger Avary': 'tt7248248,tt0110912,tt0110265...  September  -1.081039   \n",
       "5300  {'Sandra Mitrovic': 'tt6076042,tt2402157,tt102...        May  -1.378608   \n",
       "5301  {'William Olsen': 'tt0120173,tt0096770,tt00855...     August   0.755414   \n",
       "5302  {'Dick Shawn': 'tt0118688,tt0057193,tt0063462,...   February   6.156270   \n",
       "5303  {'Sean Bean': 'tt0944947,tt0167261,tt1181791,t...        May  -2.208672   \n",
       "\n",
       "                                             released_2      continent  \\\n",
       "0     0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "1     0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "2     0       1980\\n1       1980\\n2       1980\\n3   ...         Europe   \n",
       "3     0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "4     0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "...                                                 ...            ...   \n",
       "5299  0       1980\\n1       1980\\n2       1980\\n3   ...         Europe   \n",
       "5300  0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "5301  0       1980\\n1       1980\\n2       1980\\n3   ...  North America   \n",
       "5302  0       1980\\n1       1980\\n2       1980\\n3   ...         Europe   \n",
       "5303  0       1980\\n1       1980\\n2       1980\\n3   ...         Europe   \n",
       "\n",
       "     duration  \n",
       "0       Short  \n",
       "1       Short  \n",
       "2       Short  \n",
       "3        Long  \n",
       "4        Long  \n",
       "...       ...  \n",
       "5299    Short  \n",
       "5300    Short  \n",
       "5301    Short  \n",
       "5302    Short  \n",
       "5303    Short  \n",
       "\n",
       "[5304 rows x 28 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_movies.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Christopher M. Campos, Gretchen Mol, Hector E...\n",
       "1       [Adrienne Barbeau, Allison Minick, Annie Hamil...\n",
       "2       [Al Pacino, Bud S. Smith, Gerald Walker, Jerry...\n",
       "3       [Carl Foreman, Edward Albert, Gordon Thomas, I...\n",
       "4       [A. Marshal Ward, Alessandro Zangirolami, Barr...\n",
       "                              ...                        \n",
       "5299    [David Wasco, Eric Pascal Chaltiel, Eric Stolt...\n",
       "5300    [Arthur Gorson, Austin Witt, Bertha Navarro, C...\n",
       "5301    [Heather Kennedy, Jeff Edmond, Kathy Brickmeie...\n",
       "5302    [Agustin Adba, Alex Legend, Alexa Servodidio, ...\n",
       "5303    [Andrew McAlpine, David Martin, Melanie Griffi...\n",
       "Name: primaryName, Length: 5304, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-03eab0709045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmost_30\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m                 )\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-03eab0709045>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmost_30\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "feature = 'primaryName'\n",
    "train[feature]= train[feature].apply(lambda x:[g for g in x or []])\n",
    "c = Counter(sum(train[feature], []))\n",
    "most_30 = [x[0] for x in c.most_common(30)]\n",
    "train['temp_30'] = train[feature].apply(lambda x: list(set(most_30) & set(x)))\n",
    "dummies = pd.get_dummies(train['temp_30'].apply(pd.Series).stack(), prefix = feature).groupby(level=0).sum()\n",
    "\n",
    "# Join back with the original dataframe \n",
    "train = train.join(dummies)#.fillna(0)\n",
    "train.iloc[:,-30:] = train.iloc[:,29:].fillna(0)\n",
    "train.drop(columns=['temp_30'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director\n",
      "writer\n",
      "star\n",
      "country\n",
      "company\n",
      "primaryName\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Finding and binarize the features with the top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#df, df_movies = preprocess('Comprehensive IMDb Data.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_movies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'director'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'writer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'star'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'primaryName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36mbinary_features\u001b[1;34m(train, features)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Extract information from dict and convert to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Finding top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m                 )\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-da9823ec39bc>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Extract information from dict and convert to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Finding top 30 most commen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Define function for binarization of columns with the top 30 most commen ones\n",
    "\n",
    "def binary_features(train, features): \n",
    "    for feature in features:\n",
    "        print(feature)\n",
    "        # Extract information from dict and convert to list \n",
    "        train[feature]= train[feature].apply(lambda x:[x or []])\n",
    "\n",
    "        # Finding top 30 most commen \n",
    "        c = Counter(sum(train[feature], []))\n",
    "        most_30 = [x[0] for x in c.most_common(30)]\n",
    "\n",
    "        # Removing the ones that are not in the top 30 \n",
    "        train['temp_30'] = train[feature].apply(lambda x: list(set(most_30) & set(x)))\n",
    "\n",
    "        # Creat dummies \n",
    "        dummies = pd.get_dummies(train['temp_30'].apply(pd.Series).stack(), prefix = feature).groupby(level=0).sum()\n",
    "\n",
    "        # Join back with the original dataframe \n",
    "        train = train.join(dummies)\n",
    "        train.iloc[:,-30:] = train.iloc[:,-30:].fillna(0)\n",
    "\n",
    "        # Drop the temperary colum \n",
    "        train.drop(columns=['temp_30'], inplace=True)\n",
    "    return train\n",
    "\n",
    "# Finding and binarize the features with the top 30 most commen \n",
    "#df, df_movies = preprocess('Comprehensive IMDb Data.csv')\n",
    "train = binary_features(df_movies, ['director','writer','star','country','company','primaryName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='explore'></a>\n",
    "## Part 4: _<u>Exploratory component</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='conc'></a>\n",
    "## Part 5: _<u>Conclusion</u>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    ## create unique identifier of each movie \n",
    "    df['title_year'] = df['title'] + '_' + df['year'].astype(str)\n",
    "    ## create profit column\n",
    "    df['Profit'] = df['gross'] - df['budget']\n",
    "\n",
    "    #########################################################################################\n",
    "    ## create new compact datarfame\n",
    "    ## extract list of unique movie titles \n",
    "    #titles=list(set(df['title']))\n",
    "    title_year_set = list(set(df['title_year']))\n",
    "\n",
    "    # Create a dataframe where each row is a unique movie \n",
    "    movies={}\n",
    "    for t in title_year_set:\n",
    "        # Create a temperary datframe for subset of with title_year = t\n",
    "        df_temp = df[df.title_year == t]\n",
    "\n",
    "        # Extracting all the unique values for the attributes for the given title_year t\n",
    "        star = np.unique(df_temp['star'])\n",
    "        writer = np.unique(df_temp['writer'])\n",
    "        director = np.unique(df_temp['director'])\n",
    "        title = np.unique(df_temp['title'])\n",
    "        rating = np.unique(df_temp['rating'])\n",
    "        genre =np.unique(df_temp['genre'])\n",
    "        released = np.unique(df_temp['released'])\n",
    "        year = np.unique(df_temp['year'])\n",
    "        month = np.unique(df_temp['month'])\n",
    "        day = np.unique(df_temp['day'])\n",
    "        score = np.unique(df_temp['score'])\n",
    "        country = np.unique(df_temp['country'])\n",
    "        budget = np.unique(df_temp['budget'])\n",
    "        gross = np.unique(df_temp['gross'])\n",
    "        company = np.unique(df_temp['company'])\n",
    "        runtime = np.unique(df_temp['runtime'])\n",
    "        region = np.unique(df_temp['region'])\n",
    "        titleId = np.unique(df_temp['titleId'])\n",
    "        primaryName = np.unique(df_temp['primaryName'])\n",
    "\n",
    "        # Extract attributes which are based on primaryName and then as dictionaries\n",
    "        cat = {}\n",
    "        ncon = {}\n",
    "        prim = {}\n",
    "        known = {}\n",
    "        for index, row in df[df.title_year == t].iterrows():\n",
    "            pN = row['primaryName']\n",
    "            cat[pN] = row['category']\n",
    "            ncon[pN] = row['nconst']\n",
    "            known[pN] = row['knownForTitles']\n",
    "\n",
    "        movie = {'titleId': titleId, 'title':title, 'rating':rating, 'region':region, 'genre': genre, 'released': released, 'year':year,\n",
    "        'month':month, 'day':day, 'score':score, 'director':director, 'writer':writer, 'star':star, 'country':country,\n",
    "        'budget':budget, 'gross':gross, 'company':company, 'runtime': runtime, 'primaryName':primaryName, 'category':cat, 'nconst':ncon, 'knownForTitles':known}\n",
    "        movies[t]=movie\n",
    "    \n",
    "    # Construct dataframe \n",
    "    d=pd.DataFrame(movies)\n",
    "    df2=d.transpose()\n",
    "\n",
    "    df_movies = df2.copy()\n",
    "    # Finding one value for budget for each title_year\n",
    "    df_movies['budget'] = df_movies['budget'].apply(lambda x: x if len(x) == 1 else [np.nanmean(x)])\n",
    "\n",
    "    # Unpack array\n",
    "    col_unpack = ['title', 'rating', 'region', 'genre', 'released', 'year', 'month',\n",
    "        'day', 'score', 'director', 'writer', 'star', 'country', 'budget',\n",
    "        'gross', 'company', 'runtime']\n",
    "        \n",
    "    for col in col_unpack:\n",
    "        df_movies[col] = [i[0] for i in df_movies[col]]\n",
    "\n",
    "    #############################################################################\n",
    "    ## Data cleaning\n",
    "\n",
    "    # Drop missing values in budget\n",
    "    df_movies = df_movies.dropna(subset=['budget'])\n",
    "    # Dealing with missing values in rating\n",
    "    df_movies['rating'].fillna(\"Not Rated\", inplace = True) \n",
    "    df_movies['rating'] = df_movies['rating'].replace(['Unrated'],'Not Rated')\n",
    "    df_movies.fillna({'country':df_movies.country.mode().astype(str)[0],\n",
    "    'company':df_movies.company.mode().astype(str)[0],'runtime':df_movies.runtime.median()},inplace=True)\n",
    "\n",
    "    df_movies = df_movies.dropna(subset=['month'])\n",
    "\n",
    "    df_movies['released'] = pd.to_datetime(df_movies['released'],format='%Y-%m-%d')\n",
    "    df_movies = df_movies.sort_values(by= ['released'])\n",
    "\n",
    "    # Chagne type of month\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    df_movies['months'] = pd.Categorical(df_movies['month'], categories=months, ordered=True)\n",
    "\n",
    "    # Convert the gross and budget from $ to Million $ \n",
    "    df_movies['gross'] = df_movies['gross']/1000000\n",
    "    df_movies['budget'] = df_movies['budget']/1000000\n",
    "\n",
    "    df_movies = df_movies.reset_index().rename(columns = {'index':'title_year'})\n",
    "\n",
    "    ####################################################################################\n",
    "    ## add new features to df_movies\n",
    "\n",
    "    df_movies['Profit'] = df_movies['gross'] - df_movies['budget']\n",
    "\n",
    "    ## we will create new column called released_2 that only consists of year and month information of movie release\n",
    "    df_movies['released_2'] = str(df_movies['year']) + '_' + str(df_movies['month'])\n",
    "\n",
    "    df_movies['country'] = df_movies['country'].replace(['West Germany'],'Germany')\n",
    "    df_movies['country'] = df_movies['country'].replace(['Yugoslavia'],'Serbia')\n",
    "    df_movies['country'] = df_movies['country'].replace(['Federal Republic of Yugoslavia'],'Serbia')\n",
    "\n",
    "    df_movies['continent'] = df_movies['country'].apply(country_to_continent)\n",
    "\n",
    "    # Create duration column\n",
    "    df_movies['duration'] = df_movies['runtime'].apply(duration)\n",
    "\n",
    "    return df,df_movies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "\n",
    "def country_to_continent(country_name):\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "\n",
    "def duration(x):\n",
    "    if x <= 120:\n",
    "        return 'Short'\n",
    "    else:\n",
    "        return 'Long'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1d60ef3148d6d6f99d64de6ef09e0267d4db5c62a0823eaf2b9aa582c08f8e5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
